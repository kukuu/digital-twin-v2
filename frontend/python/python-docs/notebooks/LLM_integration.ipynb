{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cce5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlparse # For SQL validation\n",
    "\n",
    "# LangChain Imports\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n"
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a41ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SUPABASE_URL = os.environ.get(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.environ.get(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c28432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql(sql_query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Performs basic validation on the generated SQL query.\n",
    "    Allows only SELECT statements. Blocks DDL, DML, and potentially harmful clauses.\n",
    "    \"\"\"\n",
    "    parsed = sqlparse.parse(sql_query)[0] # parse.parse returns a list of statements\n",
    "    \n",
    "    # Check for keywords that indicate DDL or DML\n",
    "    forbidden_keywords = {'INSERT', 'UPDATE', 'DELETE', 'DROP', 'ALTER', 'TRUNCATE', 'CREATE', 'GRANT', 'REVOKE', 'VACUUM'}\n",
    "    \n",
    "    # Check if the first token is SELECT\n",
    "    if not parsed.tokens[0].normalized == 'SELECT':\n",
    "        print(f\"Validation failed: Query does not start with SELECT. Found: {parsed.tokens[0].normalized}\")\n",
    "        return False\n",
    "\n",
    "    # Iterate through tokens to find forbidden keywords\n",
    "    for token in parsed.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Token) and token.normalized in forbidden_keywords:\n",
    "            print(f\"Validation failed: Forbidden keyword found: {token.normalized}\")\n",
    "            return False\n",
    "        # Prevent UNION/UNION ALL if not specifically needed and risky for your use case\n",
    "        if isinstance(token, sqlparse.sql.Token) and token.normalized in {'UNION'}:\n",
    "             print(f\"Validation failed: UNION is forbidden for security.\")\n",
    "             return False\n",
    "\n",
    "    print(\"SQL query passed basic validation.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a364e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded database metadata from metadata.json\n"
     ]
    }
   ],
   "source": [
    "METADATA_FILE = \"metadata.json\"\n",
    "import json\n",
    "try:\n",
    "    with open(METADATA_FILE, 'r') as f:\n",
    "        db_metadata = json.load(f)\n",
    "    print(f\"Loaded database metadata from {METADATA_FILE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: {METADATA_FILE} not found. Schema descriptions will be limited.\")\n",
    "    db_metadata = {\"tables\": []}\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not parse {METADATA_FILE}. Check JSON format.\")\n",
    "    db_metadata = {\"tables\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b340db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47b5c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Fetching 3 files: 100%|██████████| 3/3 [50:29<00:00, 1009.83s/it]  \n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# run huggingface-cli login\n",
    "model_kwargs = {\n",
    "            \"load_in_4bit\": True,\n",
    "            \"torch_dtype\": torch.bfloat16,\n",
    "            \"device_map\": \"auto\"\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MISTRAL_MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MISTRAL_MODEL_NAME, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216a00f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = InferenceClient(model=MISTRAL_MODEL_NAME)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Hi! How are you? Can you explain me what are Neural Networks in short?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f129465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 15359, 28808, 1602, 460, 368, 28804, 2418, 368, 7282, 528, 767, 460, 3147, 1890, 9488, 28713, 297, 2485, 28804], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(msg)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b37ccf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "res = model.generate(tokenizer.encode(msg, return_tensors=\"pt\").to(\"cuda\"), max_new_tokens=1000, do_sample=True, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c81a8c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Hi! How are you? Can you explain me what are Neural Networks in short?',\n",
       " '',\n",
       " 'Sure! A neural network is a type of artificial intelligence model that is inspired by the human brain. It\\'s designed to recognize patterns and learn from data, much like the human brain does. Neural networks consist of interconnected nodes, or \"neurons,\" that process and transmit information. Each node takes in some input, applies a function to it, and passes the output on to the next node. The network learns by adjusting the weights of the connections between neurons based on the error of its predictions. Neural networks are particularly well-suited to tasks like image and speech recognition, where they can learn to recognize complex patterns from large amounts of data.</s>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(res[0].tolist()).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd384f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af3f9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = re.findall(r\"```sql\\n(.*?);\\n```\", msg, re.DOTALL)[0]\n",
    "q = \"\"\"SELECT AVG(\"MeterA_reading\") \\nFROM synthetic_data_01 \\nWHERE \"MeterA_reading\" BETWEEN 10 AND 30\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8560f75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleAPIResponse[~_ReturnT](data=[{'avg': 22.1793215979329}], count=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supabase.rpc(\"execute_dynamic_sql\", {\"sql_command\": q}).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb77d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


